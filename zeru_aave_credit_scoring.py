# -*- coding: utf-8 -*-
"""Zeru_aave_credit_scoring.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sfYjMtGK3RfEJdFFUBnqBKUyjjg-RHVC

Step 1: Data Loading & setup
"""



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.cluster import KMeans

from tqdm import tqdm
import json

# For cleaner plots
sns.set(style="whitegrid")

from google.colab import drive
drive.mount('/content/drive')

# Update path as per your Drive location
json_file_path = '/content/drive/MyDrive/user-wallet-transactions.json'

# Load JSON (may take time depending on file size)
with open(json_file_path, 'r') as f:
    data = json.load(f)

# Normalize nested structure into flat DataFrame
df = pd.json_normalize(data)

# Show structure for understanding
print(df.shape)
df.head()



"""Step 2: Data Exploration and Cleaning"""

pd.set_option('display.max_columns', 50)
print(df.columns.tolist())

print("Unique actions:", df['action'].unique())
print("\nAction counts:\n", df['action'].value_counts())

print(df[['userWallet', 'timestamp', 'action', 'actionData.amount', 'actionData.assetPriceUSD']].isnull().sum())

# Convert relevant fields to numeric
df['actionData.amount'] = pd.to_numeric(df['actionData.amount'], errors='coerce')
df['actionData.assetPriceUSD'] = pd.to_numeric(df['actionData.assetPriceUSD'], errors='coerce')

df['amount_usd'] = df['actionData.amount'] * df['actionData.assetPriceUSD']

df[['actionData.amount', 'actionData.assetPriceUSD', 'amount_usd']].describe()



"""Step -3: Feature Engineering

"""

#  Add a 'date' column for activity period calculation
df['date'] = pd.to_datetime(df['timestamp'], unit='s')

#  Group by 'userWallet'
group = df.groupby('userWallet')

#  Initialize feature dataframe
wallet_features = pd.DataFrame()
wallet_features['num_transactions'] = group.size()
wallet_features['num_deposit'] = group['action'].apply(lambda x: (x == 'deposit').sum())
wallet_features['num_borrow'] = group['action'].apply(lambda x: (x == 'borrow').sum())
wallet_features['num_repay'] = group['action'].apply(lambda x: (x == 'repay').sum())
wallet_features['num_redeemunderlying'] = group['action'].apply(lambda x: (x == 'redeemunderlying').sum())
wallet_features['num_liquidationcall'] = group['action'].apply(lambda x: (x == 'liquidationcall').sum())

#  USD volume-based features
wallet_features['total_deposit_usd'] = group.apply(lambda x: x.loc[x['action'] == 'deposit', 'amount_usd'].sum())
wallet_features['total_borrow_usd'] = group.apply(lambda x: x.loc[x['action'] == 'borrow', 'amount_usd'].sum())
wallet_features['total_repay_usd'] = group.apply(lambda x: x.loc[x['action'] == 'repay', 'amount_usd'].sum())
wallet_features['total_redeem_usd'] = group.apply(lambda x: x.loc[x['action'] == 'redeemunderlying', 'amount_usd'].sum())
wallet_features['total_liquidation_usd'] = group.apply(lambda x: x.loc[x['action'] == 'liquidationcall', 'amount_usd'].sum())

#  Derived ratios
wallet_features['repay_borrow_ratio'] = wallet_features['total_repay_usd'] / (wallet_features['total_borrow_usd'] + 1)
wallet_features['liquidation_rate'] = wallet_features['num_liquidationcall'] / (wallet_features['num_borrow'] + 1)
wallet_features['borrow_deposit_ratio'] = wallet_features['total_borrow_usd'] / (wallet_features['total_deposit_usd'] + 1)

#  Activity days
wallet_features['first_tx'] = group['date'].min()
wallet_features['last_tx'] = group['date'].max()
wallet_features['active_days'] = (wallet_features['last_tx'] - wallet_features['first_tx']).dt.days + 1

#  Drop helper columns if not needed
wallet_features = wallet_features.drop(['first_tx', 'last_tx'], axis=1)

# Check the feature matrix
wallet_features.reset_index(inplace=True)
wallet_features.head()



"""Step 4: Rule-based Scoring"""



from sklearn.preprocessing import MinMaxScaler

# Columns to scale
cols_to_scale = [
    'total_deposit_usd', 'total_borrow_usd', 'total_repay_usd',
    'liquidation_rate', 'repay_borrow_ratio', 'borrow_deposit_ratio',
    'active_days'
]

# Replace inf with nan and fill with 0 before scaling
wallet_features.replace([np.inf, -np.inf], np.nan, inplace=True)
wallet_features.fillna(0, inplace=True)

scaler = MinMaxScaler()
scaled_features = scaler.fit_transform(wallet_features[cols_to_scale])
scaled_df = pd.DataFrame(scaled_features, columns=[col+'_scaled' for col in cols_to_scale])

# Concatenate scaled columns
wallet_features = pd.concat([wallet_features, scaled_df], axis=1)

# Define weights
w_deposit = 0.25
w_borrow = 0.20
w_repay = 0.20
w_liquidation = 0.15
w_repay_borrow_ratio = 0.10
w_borrow_deposit_ratio = 0.05
w_active_days = 0.05

# Compute score
wallet_features['rule_based_score'] = (
    w_deposit * wallet_features['total_deposit_usd_scaled'] +
    w_borrow * wallet_features['total_borrow_usd_scaled'] +
    w_repay * wallet_features['total_repay_usd_scaled'] -
    w_liquidation * wallet_features['liquidation_rate_scaled'] +
    w_repay_borrow_ratio * wallet_features['repay_borrow_ratio_scaled'] +
    w_borrow_deposit_ratio * wallet_features['borrow_deposit_ratio_scaled'] +
    w_active_days * wallet_features['active_days_scaled']
)

# Scale to 0-1000
wallet_features['rule_based_score'] = (wallet_features['rule_based_score'] - wallet_features['rule_based_score'].min()) / \
                                      (wallet_features['rule_based_score'].max() - wallet_features['rule_based_score'].min()) * 1000

# Display results
wallet_features[['userWallet', 'rule_based_score']].head()

"""KMeans Clustering ML Pipeline

"""

from sklearn.cluster import KMeans

# Features to use
cluster_features = wallet_features[
    ['total_deposit_usd_scaled', 'total_borrow_usd_scaled', 'total_repay_usd_scaled',
     'liquidation_rate_scaled', 'repay_borrow_ratio_scaled', 'borrow_deposit_ratio_scaled',
     'active_days_scaled']
]

# Fit KMeans
kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)
wallet_features['cluster'] = kmeans.fit_predict(cluster_features)

# Map clusters to score bands
# Compute cluster-wise means to determine ordering
cluster_order = wallet_features.groupby('cluster')['total_deposit_usd_scaled'].mean().sort_values().index.tolist()

# Assign scores based on cluster rank
score_map = {}
score_bands = [200, 400, 600, 800, 1000]  # or adjust bands as needed
for idx, cluster_label in enumerate(cluster_order):
    score_map[cluster_label] = score_bands[idx]

wallet_features['ml_score'] = wallet_features['cluster'].map(score_map)

# Preview
wallet_features[['userWallet', 'rule_based_score', 'cluster', 'ml_score']].head()

"""Step 6: Generating Analysis Plots"""

import matplotlib.pyplot as plt

# Rule-based score histogram
plt.figure(figsize=(8,5))
plt.hist(wallet_features['rule_based_score'], bins=20, color='skyblue', edgecolor='black')
plt.title('Rule-Based Score Distribution')
plt.xlabel('Score')
plt.ylabel('Number of Wallets')
plt.grid(True)
plt.show()

# ML score bar plot
plt.figure(figsize=(6,4))
wallet_features['ml_score'].value_counts().sort_index().plot(kind='bar', color='salmon')
plt.title('ML Score Distribution')
plt.xlabel('ML Score Bands')
plt.ylabel('Number of Wallets')
plt.grid(True)
plt.show()

# Basic descriptive stats for README
print(wallet_features[['rule_based_score', 'ml_score']].describe())



